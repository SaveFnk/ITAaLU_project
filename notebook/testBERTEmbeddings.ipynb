{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55646e1f5350b500",
   "metadata": {},
   "source": "## Generating Feature Vectors with BERT"
  },
  {
   "cell_type": "code",
   "id": "be5a1b3673f6ef7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T20:11:10.007867Z",
     "start_time": "2024-04-16T20:11:08.952223Z"
    }
   },
   "source": [
    "from transformers import BertTokenizer, BertModel #Hugging Face Transformers\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "675c4f82c0466006",
   "metadata": {},
   "source": "### Load the Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T20:11:10.227850Z",
     "start_time": "2024-04-16T20:11:10.008651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from src.preprocessing.hatespeech_dataset_querying import prepare_hatespeech_v2_dataset, load_hatespeech_v2_dataset"
   ],
   "id": "5952d468e3325c5a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "19159a5ac94c326a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T20:11:10.475933Z",
     "start_time": "2024-04-16T20:11:10.228491Z"
    }
   },
   "source": [
    "df = load_hatespeech_v2_dataset(\"../data/hatespeech_v2/prepared_hatespeech_v2.csv\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  tweet_id                                               text  \\\n",
       "0      1344794359233998850  You know maybe doing a ‚Äúchallenge‚Äù where I dri...   \n",
       "1      1344794162625916935  RT @thehill: Black transgender woman found dea...   \n",
       "2      1344794094837637121  2021 Goals: Playtest and release Rumrunners. R...   \n",
       "3      1344790842117140483  Guest Co Host: Men Like Us Podcast #StopTheHat...   \n",
       "4      1344788907360190465  üëè Congratulations @AyodejiOsowobi @StandtoEndR...   \n",
       "...                    ...                                                ...   \n",
       "68592  1277310569700196352  Fuck you @Google @GooglePlayDev @Android With ...   \n",
       "68593  1277310293467713536  Being an Arsenal fan is tough. Even people tha...   \n",
       "68594  1277309147697106945  No subs yet? Fuck off man we aren't playing in...   \n",
       "68595  1277309020198633475  Not Manchester United again damn it ü§£ I don't ...   \n",
       "68596  1277308852493524992  FUCKING KNEW IT, OBVIOUSLY HAD TO BE MANCHESTE...   \n",
       "\n",
       "      label topic  \n",
       "0       0.0   1.0  \n",
       "1       0.0   1.0  \n",
       "2       0.0   1.0  \n",
       "3       0.0   1.0  \n",
       "4       0.0   1.0  \n",
       "...     ...   ...  \n",
       "68592   1.0   4.0  \n",
       "68593   1.0   4.0  \n",
       "68594   1.0   4.0  \n",
       "68595   2.0   4.0  \n",
       "68596   0.0   4.0  \n",
       "\n",
       "[68597 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344794359233998850</td>\n",
       "      <td>You know maybe doing a ‚Äúchallenge‚Äù where I dri...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344794162625916935</td>\n",
       "      <td>RT @thehill: Black transgender woman found dea...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344794094837637121</td>\n",
       "      <td>2021 Goals: Playtest and release Rumrunners. R...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344790842117140483</td>\n",
       "      <td>Guest Co Host: Men Like Us Podcast #StopTheHat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344788907360190465</td>\n",
       "      <td>üëè Congratulations @AyodejiOsowobi @StandtoEndR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68592</th>\n",
       "      <td>1277310569700196352</td>\n",
       "      <td>Fuck you @Google @GooglePlayDev @Android With ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68593</th>\n",
       "      <td>1277310293467713536</td>\n",
       "      <td>Being an Arsenal fan is tough. Even people tha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68594</th>\n",
       "      <td>1277309147697106945</td>\n",
       "      <td>No subs yet? Fuck off man we aren't playing in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68595</th>\n",
       "      <td>1277309020198633475</td>\n",
       "      <td>Not Manchester United again damn it ü§£ I don't ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68596</th>\n",
       "      <td>1277308852493524992</td>\n",
       "      <td>FUCKING KNEW IT, OBVIOUSLY HAD TO BE MANCHESTE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68597 rows √ó 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "95c66167110f456b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T20:11:11.204364Z",
     "start_time": "2024-04-16T20:11:10.477019Z"
    }
   },
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to process text and obtain BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize input text\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=128,           # Truncate/pad input sequences to 128 tokens\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,  # Generate attention mask\n",
    "        return_tensors='pt'       # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Get token IDs and attention mask\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get BERT embeddings (output of [CLS] token)\n",
    "    bert_embeddings = outputs[0][:, 0, :].squeeze().tolist()  # Extract embeddings of [CLS] token\n",
    "    return bert_embeddings\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "21d63bbe4841a0f8",
   "metadata": {},
   "source": [
    "### Generating BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7d8d59021fef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:29:05.849633Z",
     "start_time": "2024-04-16T20:11:11.205173Z"
    }
   },
   "source": [
    "#sample of the rows\n",
    "#df = df.sample(5000)\n",
    "\n",
    "df['bert_embeddings'] = df['text'].apply(get_bert_embeddings)\n",
    "\n",
    "# BERT embeddings:\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1344794359233998850  You know maybe doing a ‚Äúchallenge‚Äù where I dri...   \n",
       "1  1344794162625916935  RT @thehill: Black transgender woman found dea...   \n",
       "2  1344794094837637121  2021 Goals: Playtest and release Rumrunners. R...   \n",
       "3  1344790842117140483  Guest Co Host: Men Like Us Podcast #StopTheHat...   \n",
       "4  1344788907360190465  üëè Congratulations @AyodejiOsowobi @StandtoEndR...   \n",
       "\n",
       "  label topic                                    bert_embeddings  \n",
       "0   0.0   1.0  [0.16847427189350128, 0.038471419364213943, 0....  \n",
       "1   0.0   1.0  [-0.17179889976978302, -0.3453545570373535, -0...  \n",
       "2   0.0   1.0  [0.2647630572319031, -0.13153664767742157, 0.2...  \n",
       "3   0.0   1.0  [-0.2707246243953705, 0.10960787534713745, -0....  \n",
       "4   0.0   1.0  [0.06990789622068405, -0.16728679835796356, -0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344794359233998850</td>\n",
       "      <td>You know maybe doing a ‚Äúchallenge‚Äù where I dri...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.16847427189350128, 0.038471419364213943, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344794162625916935</td>\n",
       "      <td>RT @thehill: Black transgender woman found dea...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.17179889976978302, -0.3453545570373535, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344794094837637121</td>\n",
       "      <td>2021 Goals: Playtest and release Rumrunners. R...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.2647630572319031, -0.13153664767742157, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344790842117140483</td>\n",
       "      <td>Guest Co Host: Men Like Us Podcast #StopTheHat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.2707246243953705, 0.10960787534713745, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344788907360190465</td>\n",
       "      <td>üëè Congratulations @AyodejiOsowobi @StandtoEndR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.06990789622068405, -0.16728679835796356, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d54915852faf1eb9",
   "metadata": {},
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46eca141b11994",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e541c76b70e86a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:29:06.163470Z",
     "start_time": "2024-04-16T21:29:05.850197Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c43c69daf8e41732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:05:37.140378Z",
     "start_time": "2024-04-16T21:29:06.163951Z"
    }
   },
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['bert_embeddings'].tolist(), df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear') #with linear kernel\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "svm_report = classification_report(y_test, svm_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {svm_accuracy * 100:.2f}%\")  # Improve formatting to two decimal places\n",
    "print(\"Classification report:\\n\", svm_report)  # Remove unnecessary f-string"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.24%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93     10839\n",
      "         1.0       0.75      0.65      0.70      2566\n",
      "         2.0       0.54      0.19      0.29       315\n",
      "\n",
      "    accuracy                           0.88     13720\n",
      "   macro avg       0.73      0.60      0.64     13720\n",
      "weighted avg       0.87      0.88      0.87     13720\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "62ca97c63c21f176",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "id": "f86ae4372503f70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:05:37.143264Z",
     "start_time": "2024-04-16T22:05:37.141204Z"
    }
   },
   "source": "from sklearn.linear_model import LogisticRegression",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "277dd2e2ed1ae2aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:06:00.079613Z",
     "start_time": "2024-04-16T22:05:37.143872Z"
    }
   },
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "lr_report = classification_report(y_test, lr_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {lr_accuracy * 100:.2f}%\")  # Improve formatting to two decimal places\n",
    "print(\"Classification report:\\n\", lr_report)  # Remove unnecessary f-string"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.27%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93     10839\n",
      "         1.0       0.75      0.65      0.70      2566\n",
      "         2.0       0.53      0.27      0.36       315\n",
      "\n",
      "    accuracy                           0.88     13720\n",
      "   macro avg       0.73      0.62      0.66     13720\n",
      "weighted avg       0.87      0.88      0.88     13720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saveriofnk/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "5526d5d6d8f4844d",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "id": "d50c771486ddae34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:06:00.387894Z",
     "start_time": "2024-04-16T22:06:00.080561Z"
    }
   },
   "source": "from sklearn.ensemble import RandomForestClassifier",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "6d8d0801dad7a73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:07:50.590362Z",
     "start_time": "2024-04-16T22:06:00.388695Z"
    }
   },
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_report = classification_report(y_test, rf_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {rf_accuracy * 100:.2f}%\")  # Improve formatting to two decimal places\n",
    "print(\"Classification report:\\n\", rf_report)  # Remove unnecessary f-string"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.18%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.98      0.91     10839\n",
      "         1.0       0.77      0.35      0.48      2566\n",
      "         2.0       0.00      0.00      0.00       315\n",
      "\n",
      "    accuracy                           0.84     13720\n",
      "   macro avg       0.54      0.44      0.46     13720\n",
      "weighted avg       0.81      0.84      0.81     13720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saveriofnk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/saveriofnk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/saveriofnk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "384357abcd1b8fa9",
   "metadata": {},
   "source": [
    "### RNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "id": "72ac6bf2c23f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:07:50.592569Z",
     "start_time": "2024-04-16T22:07:50.590876Z"
    }
   },
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import numpy as np"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a4617fd97fc7a417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:07:50.595356Z",
     "start_time": "2024-04-16T22:07:50.592996Z"
    }
   },
   "source": [
    "# # Define the RNN model\n",
    "# class RNNClassifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "#         super(RNNClassifier, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.size(0)\n",
    "#         h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "#         out, _ = self.rnn(x, h0)\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         out = self.sigmoid(out)\n",
    "#         return out\n",
    "# \n",
    "# # Define a custom dataset for BERT embeddings\n",
    "# class BERTDataset(Dataset):\n",
    "#     def __init__(self, embeddings, labels):\n",
    "#         self.embeddings = embeddings\n",
    "#         self.labels = labels\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         return torch.FloatTensor(self.embeddings[idx]), self.labels[idx]\n",
    "# \n",
    "# # Hyperparameters\n",
    "# input_size = 768  # Size of BERT embeddings\n",
    "# hidden_size = 128  # Size of hidden layer\n",
    "# output_size = 1  # Number of output classes (binary classification)\n",
    "# num_layers = 1  # Number of RNN layers\n",
    "# learning_rate = 0.001\n",
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "# \n",
    "# \n",
    "# # Convert BERT embeddings and labels to numpy arrays\n",
    "# X = np.array(df['bert_embeddings'].tolist())\n",
    "# y = np.array(df['label'])\n",
    "# \n",
    "# # Split the data into training and testing sets (80% training, 20% testing)\n",
    "# rnn_X_train, rnn_X_test, rnn_y_train, rnn_y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Define a DataLoader for training\n",
    "# train_dataset = BERTDataset(rnn_X_train, rnn_y_train)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# \n",
    "# # Initialize RNN model, loss function, and optimizer\n",
    "# model = RNNClassifier(input_size, hidden_size, output_size, num_layers)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# \n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs.squeeze(), labels.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "# \n",
    "# # Evaluate the model on testing data\n",
    "# test_dataset = BERTDataset(rnn_X_test, rnn_y_test)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# \n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# rnn_y_true = []\n",
    "# rnn_y_true = []\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in test_loader:\n",
    "#         outputs = model(inputs)\n",
    "#         predictions = (outputs.squeeze() > 0.5).int()  # Convert probabilities to binary predictions\n",
    "#         rnn_y_true.extend(labels.tolist())\n",
    "#         rnn_y_true.extend(predictions.tolist())\n",
    "# \n",
    "# # Generate classification report\n",
    "# rnn_report = classification_report(rnn_y_true, rnn_y_true)\n",
    "# print(\"Classification Report:\")\n",
    "# print(rnn_report)"
   ],
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
