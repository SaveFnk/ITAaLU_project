{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55646e1f5350b500",
   "metadata": {},
   "source": [
    "Generating Feature Vectors with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be5a1b3673f6ef7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:59:15.852254Z",
     "start_time": "2024-04-09T15:59:15.850171Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel #Hugging Face Transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d552315e799c5ee",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c4f82c0466006",
   "metadata": {},
   "source": [
    "##### Toxigen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19159a5ac94c326a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:59:16.265479Z",
     "start_time": "2024-04-09T15:59:16.241272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asians are trying to take over the world with ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have never seen a hotter lineup in my life t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muslims deseve to di</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people who are deaf or hard of hearing should ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jews were all bad people because they're in th...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  asians are trying to take over the world with ...     hate\n",
       "1  i have never seen a hotter lineup in my life t...  neutral\n",
       "2                               muslims deseve to di     hate\n",
       "3  people who are deaf or hard of hearing should ...  neutral\n",
       "4  Jews were all bad people because they're in th...     hate"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Dataset/Toxigen-data/annotated_train.csv')\n",
    "\n",
    "df = df[['text','label']]\n",
    "df['text'] = df['text'].str[2:-2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95c66167110f456b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:59:16.906465Z",
     "start_time": "2024-04-09T15:59:16.266485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to process text and obtain BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize input text\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=128,           # Truncate/pad input sequences to 128 tokens\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,  # Generate attention mask\n",
    "        return_tensors='pt'       # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    # Get token IDs and attention mask\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get BERT embeddings (output of [CLS] token)\n",
    "    bert_embeddings = outputs[0][:, 0, :].squeeze().tolist()  # Extract embeddings of [CLS] token\n",
    "    return bert_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d63bbe4841a0f8",
   "metadata": {},
   "source": [
    "### Generating BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7d8d59021fef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:42.876908Z",
     "start_time": "2024-04-09T15:59:16.907296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>there is no such thing as an illegal immigrant...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.41316166520118713, 0.026114080101251602, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>why do you have to be so loud, i cant hear mys...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[-0.22732821106910706, 0.428143173456192, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>I spent the last year or so in Mexico and love...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.1076439917087555, 0.24130432307720184, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6831</th>\n",
       "      <td>i think it's really important to talk about th...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.10297361016273499, 0.013329430483281612, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>i can sing tha</td>\n",
       "      <td>hate</td>\n",
       "      <td>[0.19419747591018677, 0.17297789454460144, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  \\\n",
       "4560  there is no such thing as an illegal immigrant...  neutral   \n",
       "3599  why do you have to be so loud, i cant hear mys...     hate   \n",
       "7812  I spent the last year or so in Mexico and love...  neutral   \n",
       "6831  i think it's really important to talk about th...  neutral   \n",
       "699                                      i can sing tha     hate   \n",
       "\n",
       "                                        bert_embeddings  \n",
       "4560  [0.41316166520118713, 0.026114080101251602, -0...  \n",
       "3599  [-0.22732821106910706, 0.428143173456192, -0.0...  \n",
       "7812  [0.1076439917087555, 0.24130432307720184, -0.0...  \n",
       "6831  [0.10297361016273499, 0.013329430483281612, -0...  \n",
       "699   [0.19419747591018677, 0.17297789454460144, 0.0...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of the rows\n",
    "df = df.sample(5000)\n",
    "\n",
    "df['bert_embeddings'] = df['text'].apply(get_bert_embeddings)\n",
    "\n",
    "# BERT embeddings:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54915852faf1eb9",
   "metadata": {},
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46eca141b11994",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e541c76b70e86a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:07:18.767135Z",
     "start_time": "2024-04-09T16:07:18.764989Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c43c69daf8e41732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:08:00.232157Z",
     "start_time": "2024-04-09T16:07:56.544994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.74      0.74      0.74       487\n",
      "     neutral       0.75      0.75      0.75       513\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.75      0.74      0.75      1000\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['bert_embeddings'].tolist(), df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear') #with linear kernel\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "svm_report = classification_report(y_test, svm_y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca97c63c21f176",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f86ae4372503f70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:46.085352Z",
     "start_time": "2024-04-09T16:05:46.083626Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "277dd2e2ed1ae2aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:46.516043Z",
     "start_time": "2024-04-09T16:05:46.085923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.75      0.74      0.74       487\n",
      "     neutral       0.76      0.76      0.76       513\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "lr_report = classification_report(y_test, lr_y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526d5d6d8f4844d",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d50c771486ddae34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:46.518819Z",
     "start_time": "2024-04-09T16:05:46.516905Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d8d0801dad7a73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:52.120712Z",
     "start_time": "2024-04-09T16:05:46.519505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.76      0.77      0.76       487\n",
      "     neutral       0.78      0.77      0.77       513\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.77      0.77      0.77      1000\n",
      "weighted avg       0.77      0.77      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "rf_report = classification_report(y_test, rf_y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384357abcd1b8fa9",
   "metadata": {},
   "source": [
    "### RNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72ac6bf2c23f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:52.123587Z",
     "start_time": "2024-04-09T16:05:52.121843Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4617fd97fc7a417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:52.126555Z",
     "start_time": "2024-04-09T16:05:52.124308Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define the RNN model\n",
    "# class RNNClassifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "#         super(RNNClassifier, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.size(0)\n",
    "#         h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "#         out, _ = self.rnn(x, h0)\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         out = self.sigmoid(out)\n",
    "#         return out\n",
    "# \n",
    "# # Define a custom dataset for BERT embeddings\n",
    "# class BERTDataset(Dataset):\n",
    "#     def __init__(self, embeddings, labels):\n",
    "#         self.embeddings = embeddings\n",
    "#         self.labels = labels\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         return torch.FloatTensor(self.embeddings[idx]), self.labels[idx]\n",
    "# \n",
    "# # Hyperparameters\n",
    "# input_size = 768  # Size of BERT embeddings\n",
    "# hidden_size = 128  # Size of hidden layer\n",
    "# output_size = 1  # Number of output classes (binary classification)\n",
    "# num_layers = 1  # Number of RNN layers\n",
    "# learning_rate = 0.001\n",
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "# \n",
    "# \n",
    "# # Convert BERT embeddings and labels to numpy arrays\n",
    "# X = np.array(df['bert_embeddings'].tolist())\n",
    "# y = np.array(df['label'])\n",
    "# \n",
    "# # Split the data into training and testing sets (80% training, 20% testing)\n",
    "# rnn_X_train, rnn_X_test, rnn_y_train, rnn_y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Define a DataLoader for training\n",
    "# train_dataset = BERTDataset(rnn_X_train, rnn_y_train)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# \n",
    "# # Initialize RNN model, loss function, and optimizer\n",
    "# model = RNNClassifier(input_size, hidden_size, output_size, num_layers)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# \n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs.squeeze(), labels.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "# \n",
    "# # Evaluate the model on testing data\n",
    "# test_dataset = BERTDataset(rnn_X_test, rnn_y_test)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# \n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# rnn_y_true = []\n",
    "# rnn_y_true = []\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in test_loader:\n",
    "#         outputs = model(inputs)\n",
    "#         predictions = (outputs.squeeze() > 0.5).int()  # Convert probabilities to binary predictions\n",
    "#         rnn_y_true.extend(labels.tolist())\n",
    "#         rnn_y_true.extend(predictions.tolist())\n",
    "# \n",
    "# # Generate classification report\n",
    "# rnn_report = classification_report(rnn_y_true, rnn_y_true)\n",
    "# print(\"Classification Report:\")\n",
    "# print(rnn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3204a052a93f0226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:05:52.128576Z",
     "start_time": "2024-04-09T16:05:52.127237Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
