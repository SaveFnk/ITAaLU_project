{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd47a9f-d01b-4896-898f-e97934d4f342",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c99b42f-2ca0-48ec-8733-1c7d2b849310",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.preprocessing.hatespeech_dataset_querying import prepare_hatespeech_v2_dataset, load_hatespeech_v2_dataset\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../..\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparing and loading the data",
   "id": "b000fd5a0374044a"
  },
  {
   "cell_type": "code",
   "id": "48ce5f4a-31b2-4eab-a35a-2d2c391e2abf",
   "metadata": {},
   "source": [
    "# run if you need to create the preprocessed data file again\n",
    "# prepare_hatespeech_v2_dataset(save=True)\n",
    "\n",
    "df = load_hatespeech_v2_dataset()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df[\"label\"] == 2]",
   "id": "b2fb3c285f9e724d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unhcr/hatespeech-detection\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"unhcr/hatespeech-detection\")"
   ],
   "id": "c54d1ac62cdd3066",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "import tqdm \n",
    "pipe = pipeline(\"text-classification\", model=\"unhcr/hatespeech-detection\", device=\"cuda:0\")\n",
    "\n",
    "y_pred = pipe(list(df[\"text\"].values))"
   ],
   "id": "9cfa8ae1ca8de734",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Å½from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def map_predicted_to_label(y_pred):\n",
    "    y_pred_mapped = []\n",
    "    for json_pair in y_pred:\n",
    "        if json_pair[\"label\"] == \"Normal\":\n",
    "            y_pred_mapped.append(1)\n",
    "        if json_pair[\"label\"] == \"Offensive\":\n",
    "            y_pred_mapped.append(1)\n",
    "        if json_pair[\"label\"] == \"Hate speech\":\n",
    "            y_pred_mapped.append(2)\n",
    "    return y_pred_mapped\n",
    "\n",
    "\n",
    "y_truth = df[\"label\"]\n",
    "mapped_pred = map_predicted_to_label(y_pred)\n",
    "\n",
    "print(classification_report(y_truth[:100], mapped_pred))"
   ],
   "id": "fe09cac753e45dee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c3049475695c4c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# second model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IMSyPP/hate_speech_en\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"IMSyPP/hate_speech_en\")"
   ],
   "id": "787f5f358488417e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extracting features",
   "id": "bb025f2c3ed60bc"
  },
  {
   "cell_type": "code",
   "id": "92ac3023",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    porter = PorterStemmer()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"tokenized_text\"] = df[\"text\"].apply(lambda x: preprocess_text(x))\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ba53050",
   "metadata": {},
   "source": [
    "# count occurrences \n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['tokenized_text'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9cf4e558",
   "metadata": {},
   "source": [
    "# TODO finish implmentation\n",
    "word_counts = X.sum(axis=0)\n",
    "word_counts_df = pd.DataFrame(word_counts, columns=vectorizer.get_feature_names_out())\n",
    "word_counts_sorted = word_counts_df.transpose().sort_values(by=0, ascending=False)\n",
    "word_counts_sorted"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0d00b1f",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4e95a3a-3dfa-4ed7-b916-5221ed4839c5",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d50bca7e-bb15-4dd2-bdd0-05ceb120f379",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4cc9a909-2758-4bb7-b081-cbce7b2d38a5",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3392a99-e174-4f67-a6b5-9e1e2f60b81e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "362f8d26-a511-44d1-a684-6bcf4e84f9c6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
