{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd47a9f-d01b-4896-898f-e97934d4f342",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99b42f-2ca0-48ec-8733-1c7d2b849310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import plotly \n",
    "import os\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../..\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce5f4a-31b2-4eab-a35a-2d2c391e2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_df = pd.read_csv(\"data/toraman22_hate_speech_v2/Toraman22_hate_speech_v2.tsv\", sep=\"\\t\")\n",
    "\n",
    "indexes_to_drop = []\n",
    "for index, row in hate_df.iterrows():\n",
    "    try:\n",
    "        favourite_int = int(row[\"tweet_id\"])\n",
    "    except:\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "print(hate_df.shape)\n",
    "print(f\"Found {len(indexes_to_drop)} rows to drop\")\n",
    "hate_df = hate_df.drop(indexes_to_drop)\n",
    "# enforce int type on new column \n",
    "# hate_df[\"tweet_id\"] = hate_df[\"tweet_id\"].astype(np.int64)\n",
    "hate_df[\"tweet_id\"]\n",
    "print(hate_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09419632",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v2 = pd.read_csv(\"data\\hatespeech_v2\\hate_speech_dataset_v2.csv\")\n",
    "# dataset_v2_tweet_ids = set(.values)\n",
    "\n",
    "out_df = hate_df[hate_df[\"tweet_id\"].isin(dataset_v2[\"TweetID\"])]\n",
    "\n",
    "print(out_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_df[\"tweet_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba53050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4e558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d00b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_df = hate_df[hate_df[\"tweet_id\"].isin(dataset_v2_tweet_ids)]\n",
    "out_df[out_df[\"language\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e95a3a-3dfa-4ed7-b916-5221ed4839c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hatespeech_v2_dataset():\n",
    "    hate_df = pd.read_csv(\"data/toraman22_hate_speech_v2/Toraman22_hate_speech_v2.tsv\", sep='\\t')\n",
    "    # hate_df.to_csv(\"./Toraman22_hate_speech_v2.csv\", index=False)\n",
    "    hate_df[\"tweet_id\"] = hate_df[\"tweet_id\"].str.strip()   # .str.replace(\" \", \"\") , dtype={\"tweet_id\": np.int64}\n",
    "\n",
    "    counter = 0\n",
    "    for j,i in enumerate(hate_df[\"tweet_id\"]):\n",
    "        try:\n",
    "            if i != np.nan:\n",
    "                int(i)\n",
    "        except:\n",
    "            print(j, i)\n",
    "            counter += 1\n",
    "    print(\"counter\", counter)\n",
    "    # , dtype={\"tweet_id\": np.int64}\n",
    "\n",
    "    # split into training and test\n",
    "    # , dtype={\"TweetID\": np.int64}\n",
    "    dataset_v2 = pd.read_csv(\"data\\hatespeech_v2\\hate_speech_dataset_v2_labeler.csv\", dtype={\"tweet_id\": np.int64})\n",
    "    dataset_v2_tweet_ids = dataset_v2[\"TweetID\"].values.flatten()\n",
    "    print(\"dataset v2\", len(set(dataset_v2_tweet_ids)))\n",
    "\n",
    "    # for i in dataset_v2_tweet_ids:\n",
    "    #     if i not in hate_df[\"tweet_id\"]:\n",
    "    #         print(i)\n",
    "    # keep only version 2 tweets\n",
    "    # hate_df = hate_df[hate_df[\"tweet_id\"].isin(dataset_v2_tweet_ids)]\n",
    "\n",
    "    # hate_df[\"language\"].unique()\n",
    "    # only keep tweets where the language is english\n",
    "    # hate_df = hate_df[hate_df[\"language\"] == 1]\n",
    "\n",
    "    #  train_df = hate_df[hate_df[\"split\"] == \"train\"]\n",
    "    # hate_df = hate_df[[\"tweet_id\", \"text\", \"label\", \"topic\", \"user_id\"]]\n",
    "    print(len(hate_df.index))\n",
    "    return hate_df\n",
    "prepare_hatespeech_v2_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bca7e-bb15-4dd2-bdd0-05ceb120f379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
